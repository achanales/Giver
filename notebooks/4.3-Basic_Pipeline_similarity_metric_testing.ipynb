{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/insight/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['text']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/avichanales/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/avichanales/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/avichanales/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk;\n",
    "from nltk.corpus import stopwords;\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(400)\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim.matutils import sparse2full\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(400)\n",
    "\n",
    "import spacy\n",
    "nlp  = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '/Users/avichanales/Dropbox/Insight/Project/insight_project/data/interim/charity_data_cleaned_temp.csv'\n",
    "all_charity = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Pre-process raw text (lamentize and remove stopwords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS:\n",
    "            #result.append(lemmatize_stemming(token))\n",
    "            result.append(token)\n",
    "            \n",
    "    return result\n",
    "\n",
    "def preprocess_docs(docs):\n",
    "    result = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        result.append(preprocess(doc))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_charity['description_noname'] = all_charity.apply(lambda x: x['description'].replace(x['name'],\"\"),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mission_text = all_charity['description_noname'].astype('str')\n",
    "\n",
    "#Preprocess mission descriptions\n",
    "mission_text_pre = preprocess_docs(mission_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Convert pre-processed text to vectors and embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embed_charity_tfidf(processed_docs,word_min=5, word_max_perc=.2):\n",
    "    \n",
    "    'Assumes docs have already been pre-processed'\n",
    "    \n",
    "    #Create dictionary from corpus\n",
    "    docs_dict = Dictionary(processed_docs)\n",
    "    docs_dict.filter_extremes(no_below=word_min, no_above=word_max_perc)\n",
    "    docs_dict.compactify()\n",
    "    \n",
    "    #Convert docs into tf-idf vectors\n",
    "    docs_corpus = [docs_dict.doc2bow(doc) for doc in processed_docs]\n",
    "    model_tfidf = TfidfModel(docs_corpus, id2word=docs_dict)\n",
    "    docs_tfidf  = model_tfidf[docs_corpus]\n",
    "    docs_vecs   = np.vstack([sparse2full(c, len(docs_dict)) for c in docs_tfidf])\n",
    "    \n",
    "    num_docs= np.shape(docs_vecs)[0]\n",
    "    num_words = np.shape(docs_vecs)[1]\n",
    "\n",
    "    print(\"Total # of docs: {}\".format(num_docs))\n",
    "    print(\"Total # of words in dict: {}\".format(num_words))\n",
    "    \n",
    "    #For each word in dict obtain embedding vector (Glove vectors)\n",
    "    tfidf_emb_vecs = np.vstack([nlp(docs_dict[i]).vector for i in range(len(docs_dict))])\n",
    "    \n",
    "    # Weight glove vectors by tf-idf values\n",
    "    docs_emb = np.dot(docs_vecs, tfidf_emb_vecs) \n",
    "        \n",
    "    return docs_emb, docs_dict, model_tfidf, tfidf_emb_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of docs: 8370\n",
      "Total # of words in dict: 7995\n"
     ]
    }
   ],
   "source": [
    "charity_docs_emb, charity_docs_dict, charity_model_tfidf, charity_tfidf_emb_vecs = word_embed_charity_tfidf(mission_text_pre,\n",
    "                                                                                                            word_min=3, \n",
    "                                                                                                            word_max_perc=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "charity_docs_dict.save_as_text('dict_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5080"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(charity_docs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8370, 300)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(charity_docs_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Preprocess Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '/Users/avichanales/Dropbox/Insight/Project/raw_data/news_data_all.csv'\n",
    "all_news = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>publication</th>\n",
       "      <th>category</th>\n",
       "      <th>digital</th>\n",
       "      <th>section</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Agent Cooper in Twin Peaks is the audience: on...</td>\n",
       "      <td>\\nTasha Robinson\\n</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>And never more so than in Showtimeâ€™s new...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Verge</td>\n",
       "      <td>Longform</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>AI, the humanity!</td>\n",
       "      <td>\\nSam Byford\\n</td>\n",
       "      <td>2017-05-30</td>\n",
       "      <td>AlphaGoâ€™s victory isnâ€™t a defeat for hum...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Verge</td>\n",
       "      <td>Longform</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>The Viral Machine</td>\n",
       "      <td>\\nKaitlyn Tiffany\\n</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>Super Deluxe built a weird internet empi...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Verge</td>\n",
       "      <td>Longform</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>How Anker is beating Apple and Samsung at thei...</td>\n",
       "      <td>\\nNick Statt\\n</td>\n",
       "      <td>2017-05-22</td>\n",
       "      <td>Steven Yang quit his job at Google in th...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Verge</td>\n",
       "      <td>Longform</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Tour Black Pantherâ€™s reimagined homeland with ...</td>\n",
       "      <td>\\nKwame Opam\\n</td>\n",
       "      <td>2017-05-15</td>\n",
       "      <td>Ahead of Black Pantherâ€™s 2018 theatrical...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Verge</td>\n",
       "      <td>Longform</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index id                                              title  \\\n",
       "0     0  1  Agent Cooper in Twin Peaks is the audience: on...   \n",
       "1     1  2                                  AI, the humanity!   \n",
       "2     2  3                                  The Viral Machine   \n",
       "3     3  4  How Anker is beating Apple and Samsung at thei...   \n",
       "4     4  5  Tour Black Pantherâ€™s reimagined homeland with ...   \n",
       "\n",
       "                author        date  \\\n",
       "0   \\nTasha Robinson\\n  2017-05-31   \n",
       "1       \\nSam Byford\\n  2017-05-30   \n",
       "2  \\nKaitlyn Tiffany\\n  2017-05-25   \n",
       "3       \\nNick Statt\\n  2017-05-22   \n",
       "4       \\nKwame Opam\\n  2017-05-15   \n",
       "\n",
       "                                             content    year  month  \\\n",
       "0        And never more so than in Showtimeâ€™s new...  2017.0    5.0   \n",
       "1        AlphaGoâ€™s victory isnâ€™t a defeat for hum...  2017.0    5.0   \n",
       "2        Super Deluxe built a weird internet empi...  2017.0    5.0   \n",
       "3        Steven Yang quit his job at Google in th...  2017.0    5.0   \n",
       "4        Ahead of Black Pantherâ€™s 2018 theatrical...  2017.0    5.0   \n",
       "\n",
       "  publication  category  digital section  url  \n",
       "0       Verge  Longform      1.0     NaN  NaN  \n",
       "1       Verge  Longform      1.0     NaN  NaN  \n",
       "2       Verge  Longform      1.0     NaN  NaN  \n",
       "3       Verge  Longform      1.0     NaN  NaN  \n",
       "4       Verge  Longform      1.0     NaN  NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text= 'PITTSBURGH â€” Armed with an AR-15-style assault rifle and at least three handguns, a man shouting anti-Semitic slurs opened fire inside a Pittsburgh synagogue Saturday morning, killing at least 11 congregants and wounding four police officers and two others, the authorities said. In a rampage described as among the deadliest against the Jewish community in the United States, the assailant stormed into the Tree of Life Congregation, where worshipers had gathered in separate rooms to celebrate their faith, and shot indiscriminately into the crowd, shattering what had otherwise been a peaceful morning. The assailant, identified by law enforcement officials as Robert D. Bowers, fired for several minutes and was leaving the synagogue when officers, dressed in tactical gear and armed with rifles, met him at the door. According to the police, Mr. Bowers exchanged gunfire with officers before retreating back inside and barricading himself inside a third-floor room. He eventually surrendered. Mr. Bowers, 46, was injured by gunfire, although the authorities said it was unclear whether those wounds were self-inflicted or whether the police had shot him. He was taken to Allegheny General Hospital. Federal officials charged Mr. Bowers with 29 criminal counts. They included obstructing the free exercise of religious beliefs â€” a hate crime â€” and using a firearm to commit murder. He also faces state charges, including 11 counts of criminal homicide, six counts of aggravated assault and 13 counts of ethnic intimidation. The authorities said that he had no previous criminal history.Though a bris, a ceremony to mark a childâ€™s birth, was among the ceremonies taking place Saturday, no children were among the casualties, law enforcement officials said. The wounded included a 70-year-old man who had been shot in the torso, and a 61-year-old woman with soft tissue wounds, said Dr. Donald Yealy, chairman of emergency medicine at the University of Pittsburgh School of Medicine. The attack Saturday morning struck the heart of the cityâ€™s vibrant Jewish community, in the leafy Squirrel Hill neighborhood that is home to several synagogues, kosher restaurants and bakeries. Hours later, hundreds gathered at three separate interfaith vigils on a cold, rainy evening to mourn the dead and pray for the wounded. The assault on the synagogue unfolded on a quiet, drizzly morning, and came amid a bitter, vitriolic midterm election season and against the backdrop of what appears to be a surge in hate-related speech and crimes across America. It also took place in the wake of the arrest Friday morning of a man who the authorities said sent more than a dozen pipe bombs to critics of Mr. Trump, including several high-profile Democrats. Calling it the  most horrific crime scene  he had seen in 22 years with the F.B.I., Robert Jones, special agent in charge in Pittsburgh, said the synagogue was in the midst of a  peaceful service  when congregants were gunned down and  brutally murdered by a gunman targeting them simply because of their faith.   We simply cannot accept this violence as a normal part of American life,  said Gov. Tom Wolf of Pennsylvania, speaking at a news conference Saturday afternoon in Pittsburgh.  These senseless acts of violence are not who we are as Pennsylvanians and are not who we are as Americans.  The anguish of Saturdayâ€™s massacre heightened a sense of national unease over increasingly hostile political rhetoric. Critics of President Trump have argued that he is partly to blame for recent acts of violence because he has been stirring the pot of nationalism, on Twitter and at his rallies, charges that Mr. Trump has denied. About Saturdayâ€™s attack, Mr. Trump, addressing reporters at Joint Base Andrews, said:  Itâ€™s a terrible, terrible thing whatâ€™s going on with hate in our country and frankly all over the world, and something has to be done.   The results are very devastating,  he said, adding that if the temple  had some kind of protection  then  it could have been a much different situation.  Later, speaking to reporters as he got off Air Force One in Illinois, Mr. Trump said he planned to visit Pittsburgh but he did not say when. Leaders in the United States and across the world condemned the attack. Prime Minister Benjamin Netanyahu of Israel said he was  heartbroken and appalled  and that the  the entire people of Israel grieve with the families of the dead.  Attorney General Jeff Sessions said that criminal charges by the Justice Department  could lead to the death penalty.   Hatred and violence on the basis of religion can have no place in our society,  Mr. Sessions said.  Every American has the right to attend their house of worship in safety.  The massacre Saturday was at least the third mass shooting in a house of worship in three years. Last November, a gunman killed 26 worshipers at a church in Sutherland Springs, Tex., and in 2015, a white supremacist killed nine congregants in a church in Charleston, S.C. It came amid rising anxiety about illegal immigration and in a decade that has seen an uptick in hate crimes. According to an annual report by the Anti-Defamation League issued earlier this year, the number of reported anti-Semitic incidents in the United States surged 57 percent in 2017, the largest rise in a single year since the A.D.L. began tracking such crimes in 1979. The attack also was a deep and painful blow to the Jewish community in the United States, and came just days after George Soros, the billionaire philanthropist and major donor to Democratic candidates, who is Jewish and who survived Nazi occupation in Hungary, received a pipe bomb in the mail. Also in the past week, a Senate campaign sign for Josh Hawley, attorney general of Missouri, was sprayed with a swastika.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_topic_articles(df, search_term):\n",
    "    df['topic'] = all_news['content'].str.find(search_term)\n",
    "    df_sub = df[df['topic']>-1]\n",
    "    articles = df_sub['content'].astype('str')\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_topic_headlines(df, search_term):\n",
    "    df['topic'] = all_news['title'].str.find(search_term)\n",
    "    df_sub = df[df['topic']>-1]\n",
    "    return df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_topic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-0c913e0a856d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_topic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_news\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'climate change'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhomeless\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_topic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_news\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'homeless'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mjewish\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_topic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_news\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'jew'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_topic' is not defined"
     ]
    }
   ],
   "source": [
    "cc = df_topic_articles(all_news,'climate change')\n",
    "homeless = df_topic_articles(all_news,'homeless')\n",
    "jewish = df_topic(all_news,'jew')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_headline = df_topic_headlines(all_news,'climate change')\n",
    "homeless_headline = df_topic_headlines(all_news,'homeless')\n",
    "jewish_headline = df_topic_headlines(all_news,'jew')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Andrzejewski: Can Sanctuary Cities Violate Federal Law with No Consequences?'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline = jewish_headline.iloc[1,:]\n",
    "headline['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embed_articles(processed_docs,doc_dict,model_tfidf,tfidf_emb_vecs):\n",
    "    \n",
    "    #Convert docs into tf-idf vectors\n",
    "    docs_corpus = [doc_dict.doc2bow(doc) for doc in processed_docs]\n",
    "    docs_tfidf  = model_tfidf[docs_corpus]\n",
    "    docs_vecs   = np.vstack([sparse2full(c, len(doc_dict)) for c in docs_tfidf])\n",
    "    \n",
    "    \n",
    "    # sum of glove vectors linearlly weighted by tfidf \n",
    "    art_emb = np.dot(docs_vecs, tfidf_emb_vecs)\n",
    "    \n",
    "    return art_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_predict_articles(df, model,column,charity_docs_dict,charity_model_tfidf,charity_tfidf_emb_vecs):\n",
    "    \n",
    "    df_content = [df[column]]\n",
    "    df_pre = preprocess_docs(df_content)\n",
    "                    \n",
    "    art_embs = word_embed_articles(df_pre,charity_docs_dict,charity_model_tfidf,charity_tfidf_emb_vecs)\n",
    "    \n",
    "    predictions = model.predict(art_embs)\n",
    "\n",
    "    df['cluster_predictions'] = predictions\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_pred_dist(df):\n",
    "    \n",
    "    \n",
    "    df_prediction_dist = df.groupby('cluster_predictions')['index'].count().reset_index()\n",
    "    \n",
    "    sns.catplot(y='index',x='cluster_predictions',kind = 'bar', data = df_prediction_dist)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_embed_text(text,charity_docs_dict,charity_model_tfidf,charity_tfidf_emb_vecs):\n",
    "    \n",
    "    text_pre = preprocess(text)\n",
    "     \n",
    "    #Convert docs into tf-idf vectors\n",
    "    doc_corpus = charity_docs_dict.doc2bow(text_pre)\n",
    "    doc_tfidf  = charity_model_tfidf[doc_corpus]\n",
    "    doc_vec   = np.vstack([sparse2full(doc_tfidf, len(charity_docs_dict))])\n",
    "    \n",
    "    # sum of glove vectors linearlly weighted by tfidf \n",
    "    art_emb = np.dot(doc_vec, charity_tfidf_emb_vecs)\n",
    "    \n",
    "    \n",
    "    return art_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_output_n(art_emb,charity_docs_emb,topn):\n",
    "    \n",
    "    #compute cosine distance from article embedding to all charities\n",
    "    sim_to_charities = cosine_similarity(art_emb,charity_docs_emb)\n",
    "    \n",
    "    #find topN similarity scores\n",
    "    sim_scores_sorted = -np.sort(-sim_to_charities).flatten()\n",
    "    topN_scores = sim_scores_sorted[:topn]\n",
    "    \n",
    "    #find topN indices\n",
    "    indices_sorted = (-sim_to_charities).argsort().flatten()\n",
    "    topN_indices = indices_sorted[:topn].flatten()\n",
    "    \n",
    "    return topN_scores, topN_indices\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topN_ranked_charities(charity_df, topN_scores, topN_indices):\n",
    "    \n",
    "    charity_df_slim = charity_df[['name','subcategory','score','description']]\n",
    "    \n",
    "    #Extract topN charities and info\n",
    "    similar_charities = charity_df_slim.iloc[topN_indices].reset_index()\n",
    "    \n",
    "    #Add their similarity scores\n",
    "    similar_charities['sim_score'] = topN_scores\n",
    "    \n",
    "    return similar_charities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text= 'Housing and Urban Development Secretary Ben Carson defended his comments about transgender people this week in an agency-wide email late Friday afternoon, calling press reports of the remarks blatant mischaracterizations. The Washington Post reported Thursday that Carson had expressed concern in a meeting in California about big, hairy men trying to use womenâ€™s bathrooms, citing three people present who interpreted the remarks as an attack on transgender women. A leading LGBTQ advocacy group denounced Carson for the comments.'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'poverty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_emb = process_embed_text(text,charity_docs_dict,charity_model_tfidf,charity_tfidf_emb_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "topN_scores, topN_indices = compute_similarity_output_n(art_emb,charity_docs_emb,10)\n",
    "topN_charities = topN_ranked_charities(all_charity, topN_scores, topN_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>score</th>\n",
       "      <th>description</th>\n",
       "      <th>sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3244</td>\n",
       "      <td>Save the Family</td>\n",
       "      <td>Homeless Services</td>\n",
       "      <td>81.68</td>\n",
       "      <td>Save the Family equips families to address pov...</td>\n",
       "      <td>0.737888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5125</td>\n",
       "      <td>buildOn</td>\n",
       "      <td>Development and Relief Services</td>\n",
       "      <td>93.73</td>\n",
       "      <td>At home or abroad, buildOn's mission is to bre...</td>\n",
       "      <td>0.734194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3971</td>\n",
       "      <td>United Way of Charlotte County</td>\n",
       "      <td>United Ways</td>\n",
       "      <td>89.02</td>\n",
       "      <td>We are leading the united effort to eliminate ...</td>\n",
       "      <td>0.732485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4234</td>\n",
       "      <td>World Hope International</td>\n",
       "      <td>Development and Relief Services</td>\n",
       "      <td>92.92</td>\n",
       "      <td>World Hope International is a Christian relief...</td>\n",
       "      <td>0.731553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5207</td>\n",
       "      <td>BRAC USA</td>\n",
       "      <td>Development and Relief Services</td>\n",
       "      <td>85.85</td>\n",
       "      <td>The mission of BRAC and BRAC USA is to empower...</td>\n",
       "      <td>0.729067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>179</td>\n",
       "      <td>Inspiration Corporation</td>\n",
       "      <td>Homeless Services</td>\n",
       "      <td>84.09</td>\n",
       "      <td>In an atmosphere of dignity and respect, Inspi...</td>\n",
       "      <td>0.722309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6105</td>\n",
       "      <td>Christian Community Action, Connecticut</td>\n",
       "      <td>Homeless Services</td>\n",
       "      <td>87.42</td>\n",
       "      <td>Christian Community Action is a faith-based ec...</td>\n",
       "      <td>0.719255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4334</td>\n",
       "      <td>Wilkinson Center</td>\n",
       "      <td>Social Services</td>\n",
       "      <td>89.88</td>\n",
       "      <td>We help clients address barriers to self-suffi...</td>\n",
       "      <td>0.718546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4755</td>\n",
       "      <td>American Relief Agency for the Horn of Africa ...</td>\n",
       "      <td>Development and Relief Services</td>\n",
       "      <td>92.74</td>\n",
       "      <td>American Relief Agency for the Horn of Africa'...</td>\n",
       "      <td>0.713041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8037</td>\n",
       "      <td>Helping Up Mission</td>\n",
       "      <td>Homeless Services</td>\n",
       "      <td>83.22</td>\n",
       "      <td>Helping Up Mission provides hope to people exp...</td>\n",
       "      <td>0.698258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               name  \\\n",
       "0   3244                                    Save the Family   \n",
       "1   5125                                            buildOn   \n",
       "2   3971                     United Way of Charlotte County   \n",
       "3   4234                           World Hope International   \n",
       "4   5207                                           BRAC USA   \n",
       "5    179                            Inspiration Corporation   \n",
       "6   6105            Christian Community Action, Connecticut   \n",
       "7   4334                                   Wilkinson Center   \n",
       "8   4755  American Relief Agency for the Horn of Africa ...   \n",
       "9   8037                                 Helping Up Mission   \n",
       "\n",
       "                       subcategory  score  \\\n",
       "0                Homeless Services  81.68   \n",
       "1  Development and Relief Services  93.73   \n",
       "2                      United Ways  89.02   \n",
       "3  Development and Relief Services  92.92   \n",
       "4  Development and Relief Services  85.85   \n",
       "5                Homeless Services  84.09   \n",
       "6                Homeless Services  87.42   \n",
       "7                  Social Services  89.88   \n",
       "8  Development and Relief Services  92.74   \n",
       "9                Homeless Services  83.22   \n",
       "\n",
       "                                         description  sim_score  \n",
       "0  Save the Family equips families to address pov...   0.737888  \n",
       "1  At home or abroad, buildOn's mission is to bre...   0.734194  \n",
       "2  We are leading the united effort to eliminate ...   0.732485  \n",
       "3  World Hope International is a Christian relief...   0.731553  \n",
       "4  The mission of BRAC and BRAC USA is to empower...   0.729067  \n",
       "5  In an atmosphere of dignity and respect, Inspi...   0.722309  \n",
       "6  Christian Community Action is a faith-based ec...   0.719255  \n",
       "7  We help clients address barriers to self-suffi...   0.718546  \n",
       "8  American Relief Agency for the Horn of Africa'...   0.713041  \n",
       "9  Helping Up Mission provides hope to people exp...   0.698258  "
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topN_charities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The  is committed to serving the ongoing needs of the poor: food for the hungry, shelter, transitional living, and permanent housing for the homeless, jobs for the unemployed, clothing and furniture for the needy, child care for homeless children, medical and dental services for the poor, and advocacy as well as outreach for the disenfranchised. It is our belief that the poor should never be served poorly, but with love, dignity and respect. All  programs offer hospitality and friendship, while striving to meet basic needs, and help the poor attain self-sufficiency. We minister to the poor by offering them not only the necessities of life- food, shelter, and employment- but also by helping restore their sense of self worth and hope for the future.'"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topN_charities['description'][0].replace('Ministry of Caring',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['focus',\n",
       " 'renew',\n",
       " 'sto',\n",
       " 'rox',\n",
       " 'neighborhood',\n",
       " 'corpor',\n",
       " 'short',\n",
       " 'found',\n",
       " 'founder',\n",
       " 'lead',\n",
       " 'group',\n",
       " 'mobil',\n",
       " 'citizen',\n",
       " 'communiti',\n",
       " 'activist',\n",
       " 'corrupt',\n",
       " 'local',\n",
       " 'politician',\n",
       " 'creat',\n",
       " 'umbrella',\n",
       " 'organ',\n",
       " 'need',\n",
       " 'social',\n",
       " 'servic',\n",
       " 'rang',\n",
       " 'food',\n",
       " 'secur',\n",
       " 'nutrit',\n",
       " 'earli',\n",
       " 'childhood',\n",
       " 'educ',\n",
       " 'support',\n",
       " 'group',\n",
       " 'mental',\n",
       " 'health',\n",
       " 'art',\n",
       " 'program',\n",
       " 'age',\n",
       " 'small',\n",
       " 'busi',\n",
       " 'incub',\n",
       " 'grow',\n",
       " 'hous',\n",
       " 'staff',\n",
       " 'locat',\n",
       " 'mckee',\n",
       " 'rock',\n",
       " 'stow',\n",
       " 'township',\n",
       " 'aim',\n",
       " 'support',\n",
       " 'peopl',\n",
       " 'communiti',\n",
       " 'program',\n",
       " 'age',\n",
       " 'aim',\n",
       " 'develop',\n",
       " 'healthi',\n",
       " 'mind',\n",
       " 'bodi',\n",
       " 'spirit',\n",
       " 'work',\n",
       " 'wide',\n",
       " 'rang',\n",
       " 'partner',\n",
       " 'ensur',\n",
       " 'high',\n",
       " 'qualiti',\n",
       " 'program',\n",
       " 'access',\n",
       " 'resid',\n",
       " 'sto',\n",
       " 'rox',\n",
       " 'communiti']"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mission_text_pre[7286]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poverti']"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess('poverty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pos(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'DT'),\n",
       " ('Pastafarian', 'JJ'),\n",
       " ('hilariously', 'RB'),\n",
       " ('trolled', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('town', 'NN'),\n",
       " ('council', 'NN'),\n",
       " ('meeting', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('stakes', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('profoundly', 'RB'),\n",
       " ('serious', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_pos(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('Focus', 'NNP'),\n",
       " ('On', 'IN'),\n",
       " ('Renewal', 'NNP'),\n",
       " ('Sto-Rox', 'NNP'),\n",
       " ('Neighborhood', 'NNP'),\n",
       " ('Corporation', 'NNP'),\n",
       " (',', ','),\n",
       " ('or', 'CC'),\n",
       " ('FOR', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('short', 'JJ'),\n",
       " (',', ','),\n",
       " ('was', 'VBD'),\n",
       " ('founded', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('1969', 'CD'),\n",
       " ('.', '.'),\n",
       " ('FOR', 'IN'),\n",
       " ('founders', 'NNS'),\n",
       " ('led', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('group', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('mobilized', 'VBN'),\n",
       " ('citizens', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('community', 'NN'),\n",
       " ('activists', 'NNS'),\n",
       " ('against', 'IN'),\n",
       " ('corrupt', 'JJ'),\n",
       " ('local', 'JJ'),\n",
       " ('politicians', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('create', 'VB'),\n",
       " ('an', 'DT'),\n",
       " ('umbrella', 'JJ'),\n",
       " ('organization', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('much', 'JJ'),\n",
       " ('needed', 'VBN'),\n",
       " ('social', 'JJ'),\n",
       " ('services', 'NNS'),\n",
       " ('now', 'RB'),\n",
       " ('ranging', 'VBG'),\n",
       " ('from', 'IN'),\n",
       " ('food', 'NN'),\n",
       " ('security', 'NN'),\n",
       " (',', ','),\n",
       " ('nutrition', 'NN'),\n",
       " (',', ','),\n",
       " ('early-childhood', 'JJ'),\n",
       " ('education', 'NN'),\n",
       " (',', ','),\n",
       " ('support', 'NN'),\n",
       " ('groups', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('mental', 'JJ'),\n",
       " ('health', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('arts', 'NNS'),\n",
       " ('programs', 'NNS'),\n",
       " ('for', 'IN'),\n",
       " ('ages', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('small', 'JJ'),\n",
       " ('business', 'NN'),\n",
       " ('incubation', 'NN'),\n",
       " ('.', '.'),\n",
       " ('FOR', 'NNP'),\n",
       " ('has', 'VBZ'),\n",
       " ('now', 'RB'),\n",
       " ('grown', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('house', 'NN'),\n",
       " ('30+', 'CD'),\n",
       " ('staff', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('6', 'CD'),\n",
       " ('locations', 'NNS'),\n",
       " ('throughout', 'IN'),\n",
       " ('McKees', 'NNP'),\n",
       " ('Rocks', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Stowe', 'NNP'),\n",
       " ('Township', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('FOR', 'NNP'),\n",
       " ('aims', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('support', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('people', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('community', 'NN'),\n",
       " ('through', 'IN'),\n",
       " ('programs', 'NNS'),\n",
       " ('for', 'IN'),\n",
       " ('all', 'DT'),\n",
       " ('ages', 'NNS'),\n",
       " ('aimed', 'VBN'),\n",
       " ('towards', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('development', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('healthy', 'JJ'),\n",
       " ('mind', 'NN'),\n",
       " (',', ','),\n",
       " ('body', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('spirit', 'NN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('work', 'VBP'),\n",
       " ('with', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('wide', 'JJ'),\n",
       " ('range', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('partners', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('ensure', 'VB'),\n",
       " ('high', 'JJ'),\n",
       " ('quality', 'NN'),\n",
       " ('programming', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('accessible', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('all', 'DT'),\n",
       " ('13,000', 'CD'),\n",
       " ('residents', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Sto-Rox', 'NNP'),\n",
       " ('Community', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_pos(topN_charities['description'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
